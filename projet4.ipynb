{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet maison n° 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. US baby names\n",
    "\n",
    "On va s'intéresser au dataset **National data** de la SSA : https://www.ssa.gov/oact/babynames/limits.html\n",
    "\n",
    "1. Télécharger le dataset des prénoms US : https://www.ssa.gov/oact/babynames/names.zip\n",
    "\n",
    "Lire la documentation associée.\n",
    "\n",
    "2. Implémenter une fonction Python qui produit un unique DataFrame avec tous les fichiers en utilisant pandas, pas de bash :)\n",
    "\n",
    "Ordre et noms des colonnes : 'year', 'name', 'gender', 'births'\n",
    "\n",
    "Le DataFrame doit être trié selon l'année croissante puis selon l'ordre défini par les différents fichiers (voir la documentation du dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names us\n",
    "def df_names_us():\n",
    "    path = \"/Users/valentinadiproietto/Google Drive/Cambio/TelecomParisTech/MDI721KitDataScience/Settimana4/names\"\n",
    "    #all_files is a list, every element of the list is a string, given by the path of a file in the folders names which ends with txt\n",
    "    all_files = glob.glob(path + \"/*.txt\")\n",
    "    #I create an empy list li\n",
    "    li = []\n",
    "    #for every file .txt I create a dataframe as required and I append it to the list li\n",
    "    for filename in all_files:\n",
    "        dfsmall = pd.read_csv(filename, index_col=None, header = None)\n",
    "   \n",
    "        dfsmall.columns= [\"name\", \"gender\", \"births\"]\n",
    "        dfsmall[\"year\"]= filename[-8:-4]\n",
    "        dfsmall=dfsmall[[\"year\", \"name\", \"gender\", \"births\"]]\n",
    "    \n",
    "        li.append(dfsmall)\n",
    "    #I concatenate each dataframe into a big dataframe df    \n",
    "    df = pd.concat(li, axis=0)\n",
    "    #I sort the dataframe as required\n",
    "    df=df.sort_values(by=['year', 'gender', 'births','name' ], ascending=[True, True, False, True])\n",
    "    #I change the index in such a way it goes from 0 to len(df)\n",
    "    df=df.reset_index(drop= True)\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prénoms français"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va s'intéresser au dataset **Fichiers France hors Mayotte** de l'INSEE :  https://www.insee.fr/fr/statistiques/2540004/\n",
    "\n",
    "L'idée est de charger les données et ensuite de les conformer au DataFrame des prénoms US. Ainsi, toute manipulation sur le DataFrame des prénoms US pourra être directement réutilisée avec le DataFrame des prénoms français.\n",
    " \n",
    "1. Télécharger le dataset des prénoms français : https://www.insee.fr/fr/statistiques/fichier/2540004/nat2019_csv.zip\n",
    "\n",
    "\n",
    "Lire la documentation, ça peut être utile...\n",
    " \n",
    "2. Implémenter une fonction Python qui produit un DataFrame avec les prénoms français en prenant le DataFrame des prénoms US comme modèle :\n",
    " \n",
    " - Même ordre et mêmes noms des colonnes : year, name, gender, births\n",
    " - Mêmes dtypes pour les colonnes\n",
    " - Mêmes valeurs pour la colonne 'gender'\n",
    " - Seuls les prénoms de 2 caractères et plus sont conservés\n",
    " - La casse des prénoms doit être identique : initiales en majuscule, autres lettres en minuscule\n",
    " - Les lignes avec des données inutilisables doivent être supprimées\n",
    " - Les données sont triées à l'identique : années (↑), puis gender (↑), puis births (↓) et enfin name (↑)\n",
    " - L'index du DataFrame doit aller de 0 à N-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names fr\n",
    "def df_names_fr():\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(\"nat2019.csv\", sep=\";\", header =0 , names= ['gender', 'name', 'year', 'births'])\n",
    "    \n",
    "    #I rearrange the colums as required\n",
    "    df=df[[\"year\", \"name\", \"gender\", \"births\"]]\n",
    "    \n",
    "    #I realised that pyton read the name \"NA\" as float, and it puts a Nan at their place! So we do the following \n",
    "    df.loc[df['name'].apply(lambda x: isinstance(x, float)), 'name'] = 'Na'\n",
    "    \n",
    "    #I change sex from 1,2 to M,F\n",
    "    mapping = {1: 'M', 2: 'F'}\n",
    "    df['gender'] = df['gender'].map(mapping)\n",
    "    \n",
    "    #I erase the rows which have as names \"_PRENOMS_RARES\"\n",
    "    \n",
    "    df= df[df['name']!=\"_PRENOMS_RARES\"]\n",
    "    \n",
    "    #I erase the rows which have as names a string with less than 2 character\n",
    "    df=df[df['name'].str.len()>=2]\n",
    "    \n",
    "    #I erase the rows which have as year a XXXX\n",
    "    df= df[df['year']!=\"XXXX\"]\n",
    "    \n",
    "    #I chaneh the name as a string with only the first letter capital \n",
    "    df['name']=df['name'].apply(lambda x: str(x).lower().capitalize())\n",
    "    \n",
    "    #I sort, as in the us case\n",
    "    df=df.sort_values(by=['year', 'gender', 'births','name' ], ascending=[True, True, False, True])\n",
    "        \n",
    "    df=df.reset_index(drop= True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Taux de change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va s'intéresser au dataset des cours des devises de la Banque de France :  http://webstat.banque-france.fr/fr/browseBox.do?node=5385566\n",
    "\n",
    "L'idée est de charger les données, de les nettoyer et de pouvoir accéder aux cours de certaines devises à partir de leur code ISO3.\n",
    " \n",
    "1. Télécharger le dataset des taux de change : http://webstat.banque-france.fr/fr/downloadFile.do?id=5385698&exportType=csv\n",
    "\n",
    "\n",
    "2. Implémenter une fonction qui produit un DataFrame avec les taux de change par date pour une liste de codes ISO3 de devises passée en argument. L'index du DataFrame doit correspondre aux dates (voir la fonction pd.to_datetime() avec le format '%d/%m/%Y'). Les colonnes du DataFrame doivent correspondre aux devises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taux de change\n",
    "def df_taux_change(devises):\n",
    "    \n",
    "    #I import the data from line 6\n",
    "    df = pd.read_csv(\"Webstat_Export_20201025.csv\", sep =\";\", header = 5)\n",
    "    #I change the index into the format '%d/%m/%Y'\n",
    "    df[\"Source :\"]= pd.to_datetime(df[\"Source :\"], format= '%d/%m/%Y')\n",
    "    #I change the names to the columns \n",
    "    first_line= pd.read_csv(\"Webstat_Export_20201025.csv\", sep =\";\").iloc[0]\n",
    "    df.columns =first_line.apply(lambda x : x[6:9])\n",
    "    #I rename the first column as 'Dates'\n",
    "    df = df.rename(columns={'éri': 'Dates'})\n",
    "    #I put the colum 'Dates as the index'\n",
    "    df = df.set_index(df['Dates'])\n",
    "    \n",
    "    df=df.drop(columns= 'Dates')\n",
    "    df.index.name = None\n",
    "    #I replace all the \",\" with \".\"\n",
    "    df = df.apply(lambda x: x.str.replace(',','.'))\n",
    "    #I erase all the row for which I the first column ther is a string whcih contains \"-\"\n",
    "    df=df[~df[\"AUD\"].str.contains(\"-\")]\n",
    "    #I erase all the lines for which there is a  NaN\n",
    "    df=df.dropna()\n",
    "    #I cahneg all the values into numerical values\n",
    "    df =df.apply(pd.to_numeric)\n",
    "    return df[devises]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Lesson4Tests(unittest.TestCase):\n",
    "    def test_df_names_us(self):\n",
    "        df = df_names_us()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['year', 'name', 'gender', 'births'])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 1989401)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.range.RangeIndex))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "        \n",
    "    def test_df_names_fr(self):\n",
    "        df = df_names_fr()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['year', 'name', 'gender', 'births'])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 615912)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.range.RangeIndex))\n",
    "        # test names\n",
    "        self.assertTrue(df.loc[df['name'].str.contains('^[A-Z]+(?:-[A-Z]+)?$')].empty)\n",
    "        # test gender\n",
    "        self.assertEqual(len(df), len(df.loc[df['gender']=='F']) + len(df.loc[df['gender']=='M']))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "\n",
    "    def test_df_taux_change(self):\n",
    "        df = df_taux_change(['CHF', 'GBP', 'USD'])\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['CHF', 'GBP', 'USD'])\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.datetimes.DatetimeIndex))\n",
    "        # types taux\n",
    "        self.assertTrue((df.dtypes == 'float').all())\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tests\n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Lesson4Tests)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_df_names_fr (__main__.Lesson4Tests) ... ok\n",
      "test_df_names_us (__main__.Lesson4Tests) ... ok\n",
      "test_df_taux_change (__main__.Lesson4Tests) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 6.454s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
